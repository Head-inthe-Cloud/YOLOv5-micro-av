[34m[1mtrain: [0mScanning '../Cone_dataset/labels/train_cone.cache' for images and labels... 176 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<?, ?it/s][34m[1mtrain: [0mScanning '../Cone_dataset/labels/train_cone.cache' for images and labels... 176 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<?, ?it/s]
[34m[1mval: [0mScanning '../Cone_dataset/labels/train_cone.cache' for images and labels... 176 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<?, ?it/s][34m[1mtrain: [0mScanning '../Cone_dataset/labels/train_cone.cache' for images and labels... 176 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<?, ?it/s]
[34m[1mtrain: [0mScanning '../Cone_dataset/labels/train_cone.cache' for images and labels... 176 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<?, ?it/s]
[34m[1mtrain: [0mScanning '../Cone_dataset/labels/train_cone.cache' for images and labels... 176 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<?, ?it/s]
[34m[1mtrain: [0mScanning '../Cone_dataset/labels/train_cone.cache' for images and labels... 176 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<?, ?it/s]
[34m[1mtrain: [0mScanning '../Cone_dataset/labels/train_cone.cache' for images and labels... 176 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<?, ?it/s]
[34m[1mval: [0mScanning '../Cone_dataset/labels/train_cone.cache' for images and labels... 176 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<?, ?it/s]
Plotting labels... 
[34m[1mtrain: [0mScanning '../Cone_dataset/labels/train_cone.cache' for images and labels... 176 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<?, ?it/s]
[34m[1mtrain: [0mScanning '../Cone_dataset/labels/train_cone.cache' for images and labels... 176 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<?, ?it/s]
[34m[1mtrain: [0mScanning '../Cone_dataset/labels/train_cone.cache' for images and labels... 176 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<?, ?it/s]
[34m[1mval: [0mScanning '../Cone_dataset/labels/train_cone.cache' for images and labels... 176 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:01<?, ?it/s]
[34m[1mval: [0mScanning '../Cone_dataset/labels/train_cone.cache' for images and labels... 176 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:01<?, ?it/s]
[34m[1mval: [0mScanning '../Cone_dataset/labels/train_cone.cache' for images and labels... 176 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:01<?, ?it/s]
[34m[1mval: [0mScanning '../Cone_dataset/labels/train_cone.cache' for images and labels... 176 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:01<?, ?it/s]
[34m[1mval: [0mScanning '../Cone_dataset/labels/train_cone.cache' for images and labels... 176 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:01<?, ?it/s]
[34m[1mval: [0mScanning '../Cone_dataset/labels/train_cone.cache' for images and labels... 176 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:01<?, ?it/s]
[34m[1mval: [0mScanning '../Cone_dataset/labels/train_cone.cache' for images and labels... 176 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:01<?, ?it/s]
[34m[1mval: [0mScanning '../Cone_dataset/labels/train_cone.cache' for images and labels... 176 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:01<?, ?it/s]

[34m[1mautoanchor: [0mAnalyzing anchors... anchors/target = 4.38, Best Possible Recall (BPR) = 1.0000
Image sizes 640 train, 640 test
Using 8 dataloader workers
Logging results to runs/train/exp5
Starting training for 10 epochs...

     Epoch   gpu_mem       box       obj       cls     total   targets  img_size
  0%|          | 0/11 [00:00<?, ?it/s]  0%|          | 0/11 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "train.py", line 526, in <module>
    train(hyp, opt, device, tb_writer, wandb)
  File "train.py", line 292, in train
    pred = model(imgs)  # forward
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/patrick/YOLO/yolov5/models/yolo.py", line 118, in forward
    return self.forward_once(x, profile)  # single-scale inference, train
  File "/home/patrick/YOLO/yolov5/models/yolo.py", line 134, in forward_once
    x = m(x)  # run
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/patrick/YOLO/yolov5/models/common.py", line 88, in forward
    return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), dim=1))
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/patrick/YOLO/yolov5/models/common.py", line 54, in forward
    return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/patrick/YOLO/yolov5/models/common.py", line 38, in forward
    return self.act(self.bn(self.conv(x)))
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/batchnorm.py", line 131, in forward
    return F.batch_norm(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py", line 2056, in batch_norm
    return torch.batch_norm(
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 5.80 GiB total capacity; 4.51 GiB already allocated; 25.00 MiB free; 4.53 GiB reserved in total by PyTorch)
Images sizes do not match. This will causes images to be display incorrectly in the UI.
